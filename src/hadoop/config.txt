hadoop.security.groups.cache.secs=300
hadoop.registry.zk.root=/registry
fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
hadoop.http.authentication.kerberos.keytab=${user.home}/hadoop.keytab
hadoop.jetty.logs.serve.aliases=true
s3.client-write-packet-size=65536
hadoop.security.group.mapping.ldap.directory.search.timeout=10000
hadoop.work.around.non.threadsafe.getpwuid=false
io.compression.codec.bzip2.library=system-native
fs.ftp.host.port=21
net.topology.node.switch.mapping.impl=org.apache.hadoop.net.ScriptBasedMapping
hadoop.security.kms.client.encrypted.key.cache.expiry=43200000
ipc.client.connection.maxidletime=10000
fs.df.interval=60000
hadoop.registry.zk.session.timeout.ms=60000
tfile.io.chunk.size=1048576
fs.automatic.close=true
ha.health-monitor.sleep-after-disconnect.ms=1000
io.map.index.interval=128
ha.zookeeper.parent-znode=/hadoop-ha
fs.s3n.multipart.uploads.enabled=false
io.seqfile.sorter.recordlimit=1000000
hadoop.util.hash.type=murmur
fs.s3a.attempts.maximum=10
s3native.stream-buffer-size=4096
fs.AbstractFileSystem.file.impl=org.apache.hadoop.fs.local.LocalFs
io.seqfile.local.dir=${hadoop.tmp.dir}/io/local
net.topology.script.number.args=100
hadoop.http.authentication.token.validity=36000
fs.s3n.multipart.copy.block.size=5368709120
fs.s3.block.size=67108864
ha.failover-controller.graceful-fence.rpc-timeout.ms=5000
s3native.bytes-per-checksum=512
hadoop.security.group.mapping=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback
hadoop.ssl.keystores.factory.class=org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory
fs.AbstractFileSystem.hdfs.impl=org.apache.hadoop.fs.Hdfs
fs.s3.maxRetries=4
hadoop.security.random.device.file.path=/dev/urandom
hadoop.http.filter.initializers=org.apache.hadoop.http.lib.StaticUserWebFilter
hadoop.security.groups.cache.warn.after.ms=5000
io.serializations=org.apache.hadoop.io.serializer.WritableSerialization,org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization,org.apache.hadoop.io.serializer.avro.AvroReflectSerialization
fs.s3a.threads.core=15
hadoop.security.crypto.buffer.size=8192
fs.client.resolve.remote.symlinks=true
hadoop.registry.zk.retry.interval.ms=1000
hadoop.registry.secure=false
hadoop.ssl.enabled.protocols=TLSv1
hadoop.kerberos.kinit.command=kinit
rpc.metrics.quantile.enable=false
hadoop.ssl.enabled=false
io.bytes.per.checksum=512
fs.trash.interval=0
ipc.client.kill.max=10
ipc.server.listen.queue.size=128
fs.s3a.threads.max=256
ipc.client.connect.max.retries.on.timeouts=45
s3.blocksize=67108864
fs.s3.buffer.dir=${hadoop.tmp.dir}/s3
fs.s3a.threads.keepalivetime=60
fs.s3a.connection.timeout=50000
fs.s3n.block.size=67108864
nfs.exports.allowed.hosts=* rw
ha.health-monitor.connect-retry-interval.ms=1000
hadoop.security.instrumentation.requires.admin=false
file.client-write-packet-size=65536
hadoop.registry.zk.retry.ceiling.ms=60000
ha.failover-controller.cli-check.rpc-timeout.ms=20000
ha.zookeeper.acl=world:anyone:rwcda
ipc.client.connect.max.retries=10
io.file.buffer.size=4096
io.mapfile.bloom.size=1048576
hadoop.tmp.dir=/tmp/hadoop-${user.name}
hadoop.security.kms.client.authentication.retry-count=1
ipc.client.connect.retry.interval=1000
ha.failover-controller.graceful-fence.connection.retries=1
fs.swift.impl=org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem
hadoop.registry.zk.connection.timeout.ms=15000
mapreduce.client.genericoptionsparser.used=true
hadoop.security.java.secure.random.algorithm=SHA1PRNG
ftp.blocksize=67108864
hadoop.ssl.require.client.cert=false
hadoop.security.uid.cache.secs=14400
file.stream-buffer-size=4096
fs.s3a.max.total.tasks=1000
hadoop.registry.rm.enabled=false
ipc.client.idlethreshold=4000
io.skip.checksum.errors=false
ftp.stream-buffer-size=4096
fs.s3a.fast.upload=false
file.blocksize=67108864
fs.trash.checkpoint.interval=0
ftp.replication=3
hadoop.security.authorization=false
hadoop.http.authentication.simple.anonymous.allowed=true
ha.health-monitor.check-interval.ms=1000
hadoop.rpc.socket.factory.class.default=org.apache.hadoop.net.StandardSocketFactory
file.bytes-per-checksum=512
s3native.client-write-packet-size=65536
fs.har.impl.disable.cache=true
io.seqfile.lazydecompress=true
ipc.client.connect.timeout=20000
hadoop.common.configuration.version=0.23.0
hadoop.security.authentication=simple
fs.s3a.multipart.threshold=2147483647
io.map.index.skip=0
io.native.lib.available=true
s3.replication=3
file.replication=1
fs.AbstractFileSystem.har.impl=org.apache.hadoop.fs.HarFs
hadoop.security.kms.client.encrypted.key.cache.num.refill.threads=2
fs.s3n.multipart.uploads.block.size=67108864
io.mapfile.bloom.error.rate=0.005
tfile.fs.output.buffer.size=262144
fs.du.interval=600000
hadoop.security.kms.client.encrypted.key.cache.size=500
hadoop.security.group.mapping.ldap.ssl=false
fs.s3a.buffer.dir=${hadoop.tmp.dir}/s3a
fs.s3a.multipart.purge=false
fs.defaultFS=hdfs://localhost:9000
fs.s3a.multipart.size=104857600
fs.s3a.connection.establish.timeout=5000
hadoop.security.group.mapping.ldap.search.attr.member=member
hadoop.security.group.mapping.ldap.search.attr.group.name=cn
dfs.ha.fencing.ssh.connect-timeout=30000
hadoop.ssl.client.conf=ssl-client.xml
hadoop.registry.zk.quorum=localhost:2181
fs.s3a.multipart.purge.age=86400
hadoop.security.kms.client.encrypted.key.cache.low-watermark=0.3f
hadoop.user.group.static.mapping.overrides=dr.who=;
fs.s3a.fast.buffer.size=1048576
hadoop.registry.system.acls=sasl:yarn@, sasl:mapred@, sasl:hdfs@
hadoop.security.crypto.cipher.suite=AES/CTR/NoPadding
tfile.fs.input.buffer.size=262144
ha.failover-controller.new-active.rpc-timeout.ms=60000
hadoop.ssl.hostname.verifier=DEFAULT
hadoop.security.crypto.codec.classes.aes.ctr.nopadding=org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec,org.apache.hadoop.crypto.JceAesCtrCryptoCodec
hadoop.security.groups.negative-cache.secs=30
hadoop.http.authentication.type=simple
hadoop.registry.jaas.context=Client
hadoop.ssl.server.conf=ssl-server.xml
s3native.replication=3
hadoop.security.group.mapping.ldap.search.filter.group=(objectClass=group)
s3native.blocksize=67108864
hadoop.http.authentication.kerberos.principal=HTTP/_HOST@LOCALHOST
net.topology.impl=org.apache.hadoop.net.NetworkTopology
io.seqfile.compress.blocksize=1000000
hadoop.security.group.mapping.ldap.search.filter.user=(&(objectClass=user)(sAMAccountName={0}))
hadoop.registry.zk.retry.times=5
ftp.bytes-per-checksum=512
fs.AbstractFileSystem.ftp.impl=org.apache.hadoop.fs.ftp.FtpFs
s3.stream-buffer-size=4096
ftp.client-write-packet-size=65536
ipc.client.fallback-to-simple-auth-allowed=false
s3.bytes-per-checksum=512
ha.zookeeper.session-timeout.ms=5000
fs.s3a.connection.ssl.enabled=true
hadoop.rpc.protection=authentication
fs.permissions.umask-mode=022
fs.s3.sleepTimeSeconds=10
ha.health-monitor.rpc-timeout.ms=45000
hadoop.http.staticuser.user=dr.who
hadoop.http.authentication.signature.secret.file=${user.home}/hadoop-http-auth-signature-secret
fs.s3a.connection.maximum=15
fs.AbstractFileSystem.viewfs.impl=org.apache.hadoop.fs.viewfs.ViewFs
fs.s3a.paging.maximum=5000
ipc.server.max.connections=0
fs.ftp.host=0.0.0.0
